{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2695d55-d8a1-4b6c-8c0c-dd5c4812a158",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import basic libraries to handle data and build the model\n",
    "import zipfile\n",
    "import os\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader,Dataset\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import random_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7488641-a236-4060-a3b5-4937fcb1b27b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!git clone https://github.com/Prashant-AV/Qualcomm-DL-Hackathon.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f66785f-94db-44ad-ba2d-b291557569a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set device (GPU if available)\n",
    "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9983d2c2-ac44-47d4-8ede-19489fcd745f",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/content/Qualcomm-DL-Hackathon/train\")\n",
    "extract_dir = \"/content/Qualcomm-DL-Hackathon/train/\"\n",
    "os.makedirs(extract_dir, exist_ok=True)\n",
    "\n",
    "# Open and extract the zip file\n",
    "with zipfile.ZipFile(\"images part-1.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "with zipfile.ZipFile(\"images part-2.zip\", 'r') as zip_ref:\n",
    "    zip_ref.extractall(extract_dir)\n",
    "print(f\"Contents extracted to {extract_dir}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e560adc6-fa23-4427-a254-13b67de503e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.rename('/content/Qualcomm-DL-Hackathon/train/images part-1', '/content/Qualcomm-DL-Hackathon/train/images')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "744ab0e6-1eb3-4f34-bdbc-cdb76552ac8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import shutil\n",
    "for x in os.listdir('/content/Qualcomm-DL-Hackathon/train/images part-2'):\n",
    "  source_path = os.path.join('/content/Qualcomm-DL-Hackathon/train/images part-2', x)\n",
    "  shutil.move(source_path, '/content/Qualcomm-DL-Hackathon/train/images/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "516cb68d-8cb6-4467-b7d9-3fb8a3a141cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shutil.rmtree('/content/Qualcomm-DL-Hackathon/train/images')\n",
    "shutil.rmtree('/content/Qualcomm-DL-Hackathon/train/images part-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e094688f-0bb3-4287-b245-a32fc06b64e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "os.getcwd()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bddc1a6b-f06a-4a5e-8177-38f7879c69ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "#reading images to check size\n",
    "count = 0\n",
    "for x in os.listdir('/content/Qualcomm-DL-Hackathon/train/images/'):\n",
    "  img = Image.open('/content/Qualcomm-DL-Hackathon/train/images/'+x)\n",
    "  count+=1\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4746c01b-bf33-484e-b245-e83bd66b1d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "daa865e0-0f35-402d-ba72-45ea218dd1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train_data = pd.read_csv('/content/Qualcomm-DL-Hackathon/train/train.csv')\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9c4126-84b9-445a-baab-168ce2e72c1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f1b8b8-10ff-4fb8-8457-0d15c45cacad",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = pd.read_csv('/content/Qualcomm-DL-Hackathon/test.csv')\n",
    "test_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6364452c-2c93-4884-8775-9849928e1cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "train_image_names = train_data['image_names'].values\n",
    "test_image_names = test_data['image_names'].values\n",
    "\n",
    "# Initialize the LabelBinarizer\n",
    "train_labels = train_data['emergency_or_not'].values\n",
    "\n",
    "# Encode labels\n",
    "#label_binarizer = LabelBinarizer()\n",
    "#train_labels = label_binarizer.fit_transform(train_labels)\n",
    "train_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6178d686-99ad-44b1-8303-549f51e1fd32",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "train_image_paths = np.array([os.path.join('/content/Qualcomm-DL-Hackathon/train/images', file_name) for file_name in train_image_names])\n",
    "test_image_paths = np.array([os.path.join('/content/Qualcomm-DL-Hackathon/train/images', file_name) for file_name in test_image_names])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27346ed1-a2be-4a4d-a314-b53107957349",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # ImageNet mean/std\n",
    "])\n",
    "test_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a3624b8-ac30-48cd-ad79-ca7103d774ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels=None, transform=None):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image = Image.open(self.image_paths[idx]).convert('RGB')\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        if self.labels is not None:\n",
    "            label = self.labels[idx]\n",
    "            return image, label\n",
    "        else:\n",
    "            return image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "269340f6-c239-4361-a144-ae2b626214a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(image_paths=train_image_paths, labels=train_labels, transform=train_transforms)\n",
    "test_dataset = CustomDataset(image_paths=test_image_paths, transform=test_transforms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeaf06fb-0288-4d79-8c97-bc8034263414",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split training data into training and validation sets\n",
    "train_size = int(0.8 * len(train_dataset))\n",
    "val_size = len(train_dataset) - train_size\n",
    "train_data, val_data = random_split(train_dataset, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d10c74-b1af-48f4-b8d6-6d69387950e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_size, val_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf4800f5-66d9-4df6-9ed2-c075e9db5141",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 32\n",
    "train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fd5ab2-58df-43e9-8425-1d14715cbe5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the CNN model architecture (no modular code)\n",
    "conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "fc1 = nn.Linear(128 * 16 * 16, 256)\n",
    "fc2 = nn.Linear(256, 2)  # 2 classes (emergency non-emergency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46771f5d-68a9-4e22-a9d6-ff0818c08464",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = nn.Sequential(\n",
    "    conv1,\n",
    "    nn.ReLU(),\n",
    "    pool,\n",
    "    conv2,\n",
    "    nn.ReLU(),\n",
    "    pool,\n",
    "    conv3,\n",
    "    nn.ReLU(),\n",
    "    pool,\n",
    "    nn.Flatten(),\n",
    "    fc1,\n",
    "    nn.ReLU(),\n",
    "    nn.Dropout(0.3),\n",
    "    fc2,\n",
    "    nn.Softmax()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7c93b7-b94d-4fe1-b901-c9b1bb437bf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()  # for classification\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17271ea9-171d-4801-9043-9d75f38259ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "num_epochs = 7\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()  # Set the model to training mode\n",
    "    running_loss = 0.0\n",
    "    total = 0\n",
    "    correct = 0\n",
    "\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "        # Zero the parameter gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        # Backward pass and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Track the loss and accuracy\n",
    "        running_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader)\n",
    "    epoch_accuracy = 100 * correct / total\n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}, Accuracy: {epoch_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d6258e-e290-4b99-98bb-776b445fd055",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters to tune\n",
    "learning_rates = [0.001, 0.01]\n",
    "batch_sizes = [16, 32]\n",
    "dropout_rates = [0.3, 0.5]\n",
    "hidden_layers = [1, 2,3]  # 1 hidden layer or 2 hidden layers\n",
    "hidden_units = [128, 256]  # Size of each hidden layer\n",
    "num_epochs = 10\n",
    "\n",
    "# Placeholder for the best model and hyperparameters\n",
    "best_model = None\n",
    "best_accuracy = 0\n",
    "best_params = {}\n",
    "\n",
    "# Grid search loop over hyperparameters\n",
    "for lr in learning_rates:\n",
    "    for batch_size in batch_sizes:\n",
    "        for dropout_rate in dropout_rates:\n",
    "            for num_hidden_layers in hidden_layers:\n",
    "                for hidden_units_per_layer in hidden_units:\n",
    "\n",
    "                    # Recreate data loaders with the current batch size\n",
    "                    train_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\n",
    "                    val_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\n",
    "                    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "                    # Define the CNN model architecture with the current number of hidden layers and dropout rate\n",
    "                    conv1 = nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1)\n",
    "                    conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "                    conv3 = nn.Conv2d(64, 128, kernel_size=3, stride=1, padding=1)\n",
    "                    pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
    "                    fc_layers = []\n",
    "\n",
    "                    # Create hidden layers based on the number of hidden layers\n",
    "                    input_size = 128 * 16 * 16  # Image size after convolution and pooling\n",
    "                    for i in range(num_hidden_layers):\n",
    "                        fc_layers.append(nn.Linear(input_size, hidden_units_per_layer))\n",
    "                        fc_layers.append(nn.ReLU())\n",
    "                        fc_layers.append(nn.Dropout(dropout_rate))\n",
    "                        input_size = hidden_units_per_layer  # Update input size for the next layer\n",
    "\n",
    "                    fc_layers.append(nn.Linear(input_size, 5))  # Output layer for 5 classes (cycling, dancing, drinking, eating, sitting)\n",
    "\n",
    "                    # Combine layers into a model\n",
    "                    model = nn.Sequential(\n",
    "                        conv1,\n",
    "                        nn.ReLU(),\n",
    "                        pool,\n",
    "                        conv2,\n",
    "                        nn.ReLU(),\n",
    "                        pool,\n",
    "                        conv3,\n",
    "                        nn.ReLU(),\n",
    "                        pool,\n",
    "                        nn.Flatten(),\n",
    "                        *fc_layers\n",
    "                    ).to(device)\n",
    "\n",
    "                    # Define the loss function and optimizer for this combination of hyperparameters\n",
    "                    criterion = nn.CrossEntropyLoss()\n",
    "                    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "\n",
    "                    # Train the model\n",
    "                    for epoch in range(num_epochs):\n",
    "                        model.train()\n",
    "                        running_loss = 0.0\n",
    "                        correct = 0\n",
    "                        total = 0\n",
    "\n",
    "                        for inputs, labels in train_loader:\n",
    "                            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                            optimizer.zero_grad()\n",
    "                            outputs = model(inputs)\n",
    "                            loss = criterion(outputs, labels)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "\n",
    "                            running_loss += loss.item()\n",
    "                            _, predicted = torch.max(outputs, 1)\n",
    "                            total += labels.size(0)\n",
    "                            correct += (predicted == labels).sum().item()\n",
    "\n",
    "                        epoch_loss = running_loss / len(train_loader)\n",
    "                        epoch_accuracy = 100 * correct / total\n",
    "                        print(f\"Epoch [{epoch+1}/{num_epochs}] for lr={lr}, batch_size={batch_size}, dropout={dropout_rate}, hidden_layers={num_hidden_layers}, hidden_units={hidden_units_per_layer}: Loss={epoch_loss:.4f}, Accuracy={epoch_accuracy:.2f}%\")\n",
    "\n",
    "                    # Evaluate on the validation set after training\n",
    "                    model.eval()\n",
    "                    val_correct = 0\n",
    "                    val_total = 0\n",
    "                    with torch.no_grad():\n",
    "                        for inputs, labels in val_loader:\n",
    "                            inputs, labels = inputs.to(device), labels.to(device)\n",
    "                            outputs = model(inputs)\n",
    "                            _, predicted = torch.max(outputs, 1)\n",
    "                            val_total += labels.size(0)\n",
    "                            val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "                    val_accuracy = 100 * val_correct / val_total\n",
    "                    print(f\"Validation Accuracy for lr={lr}, batch_size={batch_size}, dropout={dropout_rate}, hidden_layers={num_hidden_layers}, hidden_units={hidden_units_per_layer}: {val_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b96c182a-e651-42a4-9efd-52e021c52453",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model on the validation set\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "val_correct = 0\n",
    "val_total = 0\n",
    "with torch.no_grad():\n",
    "    for inputs, labels in val_loader:\n",
    "        #inputs, labels = inputs.to(device), labels.to(device)\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        val_total += labels.size(0)\n",
    "        val_correct += (predicted == labels).sum().item()\n",
    "\n",
    "val_accuracy = 100 * val_correct / val_total\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e6dcd11-172b-4bbb-b64a-df73f4a36926",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate predictions for test images\n",
    "model.eval()  # Set the model to evaluation mode\n",
    "predictions = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "# Print or save the predictions\n",
    "print(predictions)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
